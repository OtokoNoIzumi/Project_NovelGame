{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测 chat_rag.py 文件\n",
    "file_path = \"../app.py\"\n",
    "# file_path = \"../Module/Components/state_manager.py\"\n",
    "# file_path = \"../Module/Components/config.py\"\n",
    "!flake8 {file_path} --max-line-length=240\n",
    "!pylint {file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb30623",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ..\\app_temp.py\n",
    "# pylint: disable=import-error  # Project structure requires dynamic path handling\n",
    "# pylint: disable=wrong-import-position  # Path setup must come before local imports\n",
    "\"\"\"\n",
    "For more information on `huggingface_hub` Inference API support\n",
    "please check the docs: https://huggingface.co/docs/huggingface_hub/v0.22.2/en/guides/inference\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import gradio as gr\n",
    "from google import genai\n",
    "# ===== 2. 初始化配置 =====\n",
    "# 获取当前文件所在目录的绝对路径\n",
    "if \"__file__\" in globals():\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir, \"..\"))\n",
    "else:\n",
    "    # 在 Jupyter Notebook 环境中\n",
    "    current_dir = os.getcwd()\n",
    "    current_dir = os.path.join(current_dir, \"..\")\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir))\n",
    "\n",
    "current_dir = os.path.normpath(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from Module.Components.config import get_file_path, Settings\n",
    "from Module.Components.state_manager import StateManager\n",
    "from Module.Common.scripts.llm.gemini_sdk import (\n",
    "    types,\n",
    "    get_safety_settings,\n",
    "    format_content,\n",
    "    get_content_config\n",
    ")\n",
    "from Module.Common.scripts.llm.utils.schema_response import ContentAnalyzer\n",
    "from Module.Common.scripts.common.debug_utils import log_and_print\n",
    "\n",
    "# 使用方式\n",
    "settings = Settings(current_dir=current_dir)\n",
    "\n",
    "gemini_client = genai.Client(api_key=settings.api_key)\n",
    "\n",
    "MODEL_NAME = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "\n",
    "def gemini_generate_with_schema(\n",
    "    client: Any,\n",
    "    input_text: str,\n",
    "    response_schema: Dict,\n",
    "    system_prompt: str = \"\"\n",
    ") -> Any:\n",
    "    \"\"\"使用Gemini生成带schema的响应\n",
    "\n",
    "    Args:\n",
    "        client: Gemini客户端实例\n",
    "        input_text: 输入文本\n",
    "        response_schema: 响应schema定义\n",
    "        system_prompt: 系统提示词\n",
    "\n",
    "    Returns:\n",
    "        生成的响应内容\n",
    "    \"\"\"\n",
    "    return client.models.generate_content(\n",
    "        model=MODEL_NAME,\n",
    "        contents=[format_content(\"user\", input_text)],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_prompt,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=response_schema,\n",
    "            safety_settings=get_safety_settings(),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def game_response_formatter(response: Any) -> Dict[str, Any]:\n",
    "    \"\"\"格式化游戏响应\n",
    "\n",
    "    Args:\n",
    "        response: 原始响应内容\n",
    "\n",
    "    Returns:\n",
    "        格式化后的响应字典\n",
    "    \"\"\"\n",
    "    if settings.config.get(\"log_level\", \"\") == \"debug\":\n",
    "        log_and_print(\"game_response_formatter:\\n\", response.text)\n",
    "    updates = json.loads(response.text)\n",
    "\n",
    "    state_updates = updates.get('stateUpdates', [])\n",
    "\n",
    "    updates['stateUpdates'] = [u for u in state_updates if u is not None]\n",
    "\n",
    "    return {\n",
    "        'inventory': updates.get('itemUpdates', []),\n",
    "        'character_state': updates.get('stateUpdates', [])\n",
    "    }\n",
    "\n",
    "\n",
    "def game_context_formatter(current_data: Dict[str, Any], content: str) -> str:\n",
    "    \"\"\"格式化游戏上下文\n",
    "\n",
    "    Args:\n",
    "        current_data: 当前游戏数据\n",
    "        content: 内容文本\n",
    "\n",
    "    Returns:\n",
    "        格式化后的上下文字符串\n",
    "    \"\"\"\n",
    "    # 获取配置\n",
    "    state_config = settings.config[\"state_analysis\"]\n",
    "    extra_state_attribute = settings.config.get(\"extra_state_attributes\", [])\n",
    "\n",
    "    # 构建规则和提示\n",
    "    rules = \"\\n\".join(f\"- {rule}\" for rule in state_config[\"rules\"])\n",
    "    extra_state_hint = \"\"\n",
    "\n",
    "    # 构建状态内容\n",
    "    character_state = current_data.get('character_state', {})\n",
    "\n",
    "    formatted_state = []\n",
    "    for attr, state in character_state.items():\n",
    "        if attr and state:\n",
    "            formatted_state.append(f\"{attr}: {state['state'] if state['state'] else '暂无'}\")\n",
    "            # formatted_state.append(f\"{attr}: {state['state']}\")\n",
    "    final_state = \"- \" + '\\n- '.join(formatted_state)\n",
    "\n",
    "    state_content = f\"\"\"\n",
    "故事发生前的状态\n",
    "【物品清单】\n",
    "{current_data.get('inventory', {})}\n",
    "\n",
    "【角色状态】\n",
    "{final_state}\n",
    "\"\"\"\n",
    "    # 构建完整内容\n",
    "    formatted_content = state_config[\"template\"].format(\n",
    "        rules=rules,\n",
    "        extra_hint=extra_state_hint\n",
    "    ) + state_content\n",
    "\n",
    "    # Debug日志\n",
    "    if settings.config.get(\"log_level\", \"\") == \"debug\":\n",
    "        log_and_print(\"game_context_formatter:\\n\", formatted_content + \"【最近故事内容】\\n\")\n",
    "\n",
    "    # 返回带故事内容的完整格式\n",
    "    return formatted_content + f\"\"\"\n",
    "【最近故事内容】\n",
    "{content}\n",
    "【最近故事内容】\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def game_extra_response_formatter(response: Any) -> Dict[str, Any]:\n",
    "    \"\"\"格式化额外属性响应\"\"\"\n",
    "    if settings.config.get(\"log_level\", \"\") == \"debug\":\n",
    "        log_and_print(\"game_extra_response_formatter:\\n\", response.text)\n",
    "    updates = json.loads(response.text)\n",
    "    state_updates = updates.get('stateUpdates', [])\n",
    "    extra_state_attribute = settings.config.get(\"extra_state_attributes\", [])[0]\n",
    "    for update in state_updates:\n",
    "        if 'new_value' in update:\n",
    "            update[extra_state_attribute] = update.pop('new_value')\n",
    "    return {'stateUpdates': state_updates}\n",
    "\n",
    "\n",
    "def game_extra_context_formatter(base_result: Dict, current_data: Dict) -> str:\n",
    "    \"\"\"游戏特定的额外评估上下文格式化\"\"\"\n",
    "    changes = []\n",
    "    extra_attrs = settings.config.get('extra_state_attributes', [])\n",
    "    attr_names = settings.config.get('state_attribute_names', {})\n",
    "    guidance = settings.config.get('extra_value_evaluation', {}).get('guidance', [])\n",
    "\n",
    "    for update in base_result.get('stateUpdates', []):\n",
    "        attr = update['attribute']\n",
    "        current_state = current_data.get('character_state', {}).get(attr, {})\n",
    "        if update['to_state'] != current_state.get('state', ''):\n",
    "            changes.extend([\n",
    "                f\"属性：{attr}\",\n",
    "                f\"初始状态：{current_state.get('state', '')}\",\n",
    "                f\"变化后的状态：{update['to_state']}\"\n",
    "            ])\n",
    "            # 添加所有配置的extra属性\n",
    "            for extra_attr in extra_attrs:\n",
    "                attr_name = attr_names.get(extra_attr, extra_attr)\n",
    "                changes.append(\n",
    "                    f\"初始{attr_name}值：{current_state.get(extra_attr, 0)}\"\n",
    "                )\n",
    "            changes.append(\"\")  # 添加空行分隔\n",
    "\n",
    "    result = \"\"\n",
    "    if changes:\n",
    "        result = \"\\n\".join(guidance) + \"\\n\" + \"\\n\".join(changes)\n",
    "\n",
    "    if settings.config.get(\"log_level\", \"\") == \"debug\":\n",
    "        log_and_print(\"game_extra_context_formatter:\\n\", result, \"\\n id:\", chat_data.get('current_id', 0))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def game_merge_updates(base_result: Dict, extra_result: Dict) -> Dict:\n",
    "    \"\"\"游戏特定的更新合并策略\"\"\"\n",
    "    base_updates = base_result.get('character_state', [])\n",
    "    extra_updates = extra_result.get('stateUpdates', [])\n",
    "\n",
    "    # 记录每个属性首次出现的位置和更新\n",
    "    seen_attrs = {}\n",
    "    final_updates = []\n",
    "\n",
    "    # 检查是否有extra属性用于比较\n",
    "    extra_state_attributes = settings.config.get(\"extra_state_attributes\", [])\n",
    "    extra_state_attribute = extra_state_attributes[0] if extra_state_attributes else None\n",
    "\n",
    "    # 处理基础更新\n",
    "    for update in base_updates:\n",
    "        attr = update['attribute']\n",
    "        # 标准化更新数据格式\n",
    "        normalized_update = {\n",
    "            'attribute': attr,\n",
    "            'from_state': update.get('from_state'),\n",
    "            'state': update.get('to_state'),  # 统一使用 state 作为键名\n",
    "            **{k: v for k, v in update.items() if k not in ['attribute', 'from_state', 'to_state', 'state']}\n",
    "        }\n",
    "\n",
    "        if attr in seen_attrs:\n",
    "            prev_idx = seen_attrs[attr]\n",
    "            prev_update = final_updates[prev_idx]\n",
    "\n",
    "            if (extra_state_attribute in update and\n",
    "                extra_state_attribute in prev_update):\n",
    "                # 如果新的extra值更大，则替换旧的更新\n",
    "                if update[extra_state_attribute] > prev_update[extra_state_attribute]:\n",
    "                    final_updates[prev_idx] = normalized_update\n",
    "            else:\n",
    "                # 没有extra属性时保留后出现的更新\n",
    "                final_updates[prev_idx] = normalized_update\n",
    "        else:\n",
    "            seen_attrs[attr] = len(final_updates)\n",
    "            final_updates.append(normalized_update)\n",
    "\n",
    "    # 处理额外属性更新\n",
    "    for extra in extra_updates:\n",
    "        attr = extra['attribute']\n",
    "        if attr in seen_attrs:\n",
    "            idx = seen_attrs[attr]\n",
    "            # 将额外属性合并到对应的更新中\n",
    "            final_updates[idx].update({\n",
    "                k: v for k, v in extra.items()\n",
    "                if k != 'attribute'\n",
    "            })\n",
    "\n",
    "    # 构建最终结果\n",
    "    result = {k: v for k, v in base_result.items() if k != 'character_state'}\n",
    "    result['character_state'] = final_updates\n",
    "    result['extraUpdates'] = extra_result\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# 创建分析器实例\n",
    "analyzer = ContentAnalyzer(\n",
    "    llm_client=gemini_client,\n",
    "    generate_func=gemini_generate_with_schema,\n",
    "    response_schema=settings.response_schema,\n",
    "    system_prompt=settings.state_system_prompt,\n",
    "    context_formatter=game_context_formatter,\n",
    "    response_formatter=game_response_formatter,\n",
    "    # 额外评估配置\n",
    "    extra_schema=settings.config.get('extra_value_evaluation', {}).get('schema'),\n",
    "    extra_prompt=settings.config.get('extra_value_evaluation', {}).get('system_role'),\n",
    "    extra_context_formatter=game_extra_context_formatter,\n",
    "    extra_response_formatter=game_extra_response_formatter,\n",
    "    merge_updates=game_merge_updates\n",
    ")\n",
    "\n",
    "\n",
    "def get_gradio_version() -> str:\n",
    "    \"\"\"获取Gradio版本号\n",
    "\n",
    "    Returns:\n",
    "        Gradio版本号字符串\n",
    "    \"\"\"\n",
    "    return gr.__version__\n",
    "\n",
    "\n",
    "def create_initial_state() -> Dict:\n",
    "    \"\"\"创建初始游戏状态\n",
    "\n",
    "    Returns:\n",
    "        包含初始状态的字典\n",
    "    \"\"\"\n",
    "    initial_state = {\n",
    "        \"gr_version\": get_gradio_version(),\n",
    "        \"story_chapter\": \"起因\",\n",
    "        \"story_chapter_stage\": 1,\n",
    "        \"inventory\": {},\n",
    "        \"character_state\": {}\n",
    "    }\n",
    "    # 深度拷贝确保完全隔离\n",
    "    for attr in settings.config[\"state_attributes\"]:\n",
    "        initial_state[\"character_state\"][attr] = {\n",
    "            \"state\": \"\",  # 主状态\n",
    "        }\n",
    "        # 添加额外属性\n",
    "        for extra_attr in settings.config.get(\"extra_state_attributes\", []):\n",
    "            initial_state[\"character_state\"][attr][extra_attr] = -1\n",
    "    return initial_state\n",
    "\n",
    "\n",
    "game_state = create_initial_state()\n",
    "\n",
    "state_manager = StateManager(create_initial_state(), settings.config)\n",
    "\n",
    "# 区分用于处理的历史记录和用于显示的历史记录\n",
    "# 使用字典来存储对话历史和当前ID\n",
    "chat_data = {\n",
    "    \"current_id\": 0,\n",
    "    \"history\": []  # 列表中存储对话记录字典，每条记录包含role、content、only_for_display和id属性\n",
    "}\n",
    "\n",
    "\n",
    "def detect_state_changes(game_state_dict: dict, story_output: str) -> Dict:\n",
    "    \"\"\"检测游戏状态变化\n",
    "\n",
    "    Args:\n",
    "        game_state_dict: 当前游戏状态字典\n",
    "        story_output: 故事输出文本\n",
    "\n",
    "    Returns:\n",
    "        状态更新信息\n",
    "    \"\"\"\n",
    "    updates = analyzer.analyze(game_state_dict, story_output)\n",
    "    return state_manager.apply_updates(updates)\n",
    "\n",
    "\n",
    "def _handle_special_messages(message: str, history: List[Tuple[str, str]], ignore_job: str) -> str:\n",
    "    \"\"\"处理特殊消息命令\"\"\"\n",
    "    jobs_config = settings.config.get(\"explored_jobs\", {})\n",
    "\n",
    "    def apply_jobs_template(template_text: str) -> str:\n",
    "        \"\"\"应用职业排除模板\"\"\"\n",
    "        if message == jobs_config.get(\"trigger\") and '{explored_jobs}' in template_text:\n",
    "            explored_text = jobs_config[\"template\"].format(jobs=ignore_job) if ignore_job else \"\"\n",
    "            return template_text.format(explored_jobs=explored_text)\n",
    "        return template_text\n",
    "\n",
    "    if message == \"开始\" and not history:\n",
    "        begin_message = settings.begin\n",
    "        if settings.config[\"initial_state\"]:\n",
    "            begin_message += (\n",
    "                \"\\n请在应当确认随机内容的时机一并初始化状态和持有物品，状态属性清单如下：\\n\" +\n",
    "                \"\\n\".join(settings.config[\"state_attributes\"])\n",
    "            )\n",
    "        return apply_jobs_template(begin_message)\n",
    "\n",
    "    if message == \"确认\" and len(history) == 2:\n",
    "        return apply_jobs_template(settings.confirm)\n",
    "\n",
    "    return message\n",
    "\n",
    "\n",
    "def _should_append_state(message: str) -> Tuple[bool, bool, str]:\n",
    "    \"\"\"判断是否需要附加状态信息\n",
    "\n",
    "    Args:\n",
    "        message: 输入的消息\n",
    "\n",
    "    Returns:\n",
    "        Tuple[bool, bool, str]:\n",
    "        - 是否需要附加状态\n",
    "        - 是否是控制命令\n",
    "        - 处理后的消息\n",
    "    \"\"\"\n",
    "    # 检查是否是控制命令\n",
    "    is_control = message.startswith('ct')\n",
    "    processed_message = message[2:].strip() if is_control else message\n",
    "\n",
    "    # 判断是否需要附加状态（控制命令一定不附加，其他情况按原有逻辑判断）\n",
    "    should_append = False if is_control else (\n",
    "        game_state[\"story_chapter_stage\"] > 1 or\n",
    "        game_state[\"story_chapter\"] != \"起因\" or\n",
    "        chat_data[\"current_id\"] > 1\n",
    "    )\n",
    "\n",
    "    return should_append, is_control, processed_message\n",
    "\n",
    "\n",
    "def _process_response(chunk: Any, response: str) -> Tuple[str, bool]:\n",
    "    \"\"\"处理响应块，返回更新的响应和是否需要中断\"\"\"\n",
    "    if not chunk.text:\n",
    "        return response, False\n",
    "\n",
    "    if \"状态变化：\" in chunk.text:\n",
    "        response += chunk.text.split(\"状态变化：\")[0]\n",
    "        return response, True\n",
    "\n",
    "    if (\"【情节完成】\" in chunk.text) and (chat_data[\"current_id\"] > 1):\n",
    "        response += chunk.text.split(\"【情节完成】\")[0] + \"【情节完成】\"\n",
    "        return response, True\n",
    "\n",
    "    return response + chunk.text, False\n",
    "\n",
    "\n",
    "def build_contents(message=None, before_message=None):\n",
    "    \"\"\"构建内容列表\"\"\"\n",
    "    contents = []\n",
    "    for val in chat_data[\"history\"]:\n",
    "        if val.get(\"only_for_display\", False):\n",
    "            continue\n",
    "        contents.append(format_content(\n",
    "            val[\"role\"],\n",
    "            val[\"content\"]\n",
    "        ))\n",
    "\n",
    "    if before_message:\n",
    "        contents.append(format_content(\n",
    "            \"assistant\",\n",
    "            before_message\n",
    "        ))\n",
    "\n",
    "    if message:\n",
    "        contents.append(format_content(\n",
    "            \"user\",\n",
    "            message\n",
    "        ))\n",
    "    return contents\n",
    "\n",
    "\n",
    "def respond(\n",
    "    message: str,\n",
    "    history: List[Tuple[str, str]],\n",
    "    use_system_message: bool,\n",
    "    add_extra_message: bool,\n",
    "    auto_analysis_state: bool,\n",
    "    ignore_job: str,\n",
    ") -> str:\n",
    "    \"\"\"处理用户输入并生成响应\n",
    "\n",
    "    Args:\n",
    "        message: 用户输入消息\n",
    "        history: 对话历史\n",
    "        use_system_message: 是否使用系统消息\n",
    "        ignore_job: 要忽略的职业\n",
    "\n",
    "    Returns:\n",
    "        生成的响应文本\n",
    "    \"\"\"\n",
    "    # 构建对话历史\n",
    "    message = _handle_special_messages(message, history, ignore_job)\n",
    "    # 判断是否需要附加状态信息\n",
    "\n",
    "    should_append, is_control, message = _should_append_state(message)\n",
    "\n",
    "    if (should_append) and (add_extra_message):\n",
    "        message += state_manager.get_state_str()\n",
    "\n",
    "    if message:\n",
    "        # 处理普通消息\n",
    "        contents = build_contents(message)\n",
    "        response = \"\"\n",
    "        config = get_content_config(use_system_message, settings.system_role)\n",
    "        chat_data[\"current_id\"] += 1\n",
    "        chat_data[\"history\"].append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message,\n",
    "            \"idx\": chat_data[\"current_id\"]\n",
    "        })\n",
    "        if settings.config.get(\"log_level\", \"\") in [\"debug\", \"info\"]:\n",
    "            separator = \"\\n\" + \"★\"*30 + \"《CONTENT START》\" + \"★\"*30 + \"\\n\"\n",
    "            separator_end = \"\\n\" + \"☆\"*30 + \"《CONTENT END》\" + \"☆\"*30 + \"\\n\"\n",
    "            log_and_print(\"content before main response:\\n\", separator, message, separator_end)\n",
    "\n",
    "        for chunk in gemini_client.models.generate_content_stream(\n",
    "            model=MODEL_NAME,\n",
    "            contents=contents,\n",
    "            config=config\n",
    "        ):\n",
    "            response, should_break = _process_response(chunk, response)\n",
    "            yield response\n",
    "            if should_break:\n",
    "                break\n",
    "\n",
    "        if settings.config.get(\"log_level\", \"\") in [\"debug\", \"info\"]:\n",
    "            log_and_print(\"after main response:\\n\", response)\n",
    "\n",
    "        chat_data[\"history\"].append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response,\n",
    "            \"idx\": chat_data[\"current_id\"]\n",
    "        })\n",
    "\n",
    "        if not is_control and auto_analysis_state:\n",
    "            updates_str, _ = detect_state_changes(state_manager.get_state(), response)\n",
    "            if updates_str:\n",
    "                chat_data[\"history\"].append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": updates_str,\n",
    "                    \"only_for_display\": True,\n",
    "                    \"idx\": chat_data[\"current_id\"]\n",
    "                })\n",
    "                if \"状态变化：\" in response:\n",
    "                    yield response + \"\\n\" + updates_str\n",
    "                else:\n",
    "                    yield response + \"\\n状态变化：\\n\" + updates_str\n",
    "\n",
    "\n",
    "with gr.Blocks(theme=\"soft\") as demo:\n",
    "    # 1. 创建界面组件\n",
    "    chatbot = gr.ChatInterface(\n",
    "        respond,\n",
    "        title=settings.config[\"title\"],\n",
    "        type=\"messages\",\n",
    "        # examples=[[\"开始\",True,settings.config.get(\"explored_jobs\", {}).get(\"default\", \"\")]],\n",
    "        chatbot=gr.Chatbot(\n",
    "            placeholder=\"输入 【开始】 开始进行创作\",\n",
    "            height=\"80vh\",\n",
    "            # show_share_button=True,\n",
    "            editable=\"user\",\n",
    "            show_copy_all_button=True,\n",
    "            type=\"messages\",\n",
    "        ),\n",
    "        additional_inputs=[\n",
    "            # gr.Row([\n",
    "            gr.Checkbox(value=True, label=\"Use system message\"),\n",
    "            gr.Checkbox(value=True, label=\"Add Extra message\"),\n",
    "            gr.Checkbox(value=True, label=\"Auto analysis state\"),\n",
    "            # ]),\n",
    "            gr.Textbox(\n",
    "                value=settings.config.get(\"explored_jobs\", {}).get(\"default\", \"\"),\n",
    "                label=\"ignore job\"\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # 2. 创建状态显示组件\n",
    "    outputs = []\n",
    "    with gr.Accordion(\"查看故事状态\", open=False):\n",
    "        state_output = gr.JSON(value=state_manager.get_state())\n",
    "        outputs.append(state_output)\n",
    "\n",
    "    if settings.config[\"show_chat_history\"]:\n",
    "        with gr.Accordion(\"查看历史对话\", open=False):\n",
    "            history_output = gr.JSON(value=chat_data[\"history\"])\n",
    "            outputs.append(history_output)\n",
    "\n",
    "    # 3. 定义事件处理函数（保持全局状态访问）\n",
    "    def update_state() -> List[Any]:\n",
    "        return ([state_manager.get_state(), chat_data[\"history\"]]\n",
    "                if settings.config[\"show_chat_history\"]\n",
    "                else state_manager.get_state())\n",
    "\n",
    "    def clear_state() -> List[Any]:\n",
    "        chat_data['current_id'] = 0\n",
    "        chat_data['history'] = []\n",
    "        state_manager.state = create_initial_state()\n",
    "        state_manager.state_history = create_initial_state()\n",
    "        return update_state()\n",
    "\n",
    "    def undo_state() -> List[Any]:\n",
    "        if chat_data[\"current_id\"] > 0:\n",
    "            chat_data[\"history\"] = [\n",
    "                msg for msg in chat_data[\"history\"]\n",
    "                if msg[\"idx\"] != chat_data[\"current_id\"]\n",
    "            ]\n",
    "            chat_data[\"current_id\"] -= 1\n",
    "        state_manager.reset_state()\n",
    "        return update_state()\n",
    "\n",
    "    # 4. 绑定事件处理\n",
    "    chatbot.chatbot.change(fn=update_state, outputs=outputs)\n",
    "    chatbot.chatbot.clear(fn=clear_state, outputs=outputs)\n",
    "    chatbot.chatbot.undo(fn=undo_state, outputs=outputs)\n",
    "    chatbot.chatbot.retry(fn=undo_state, outputs=outputs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    # 在程序启动前添加以下代码\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "    try:\n",
    "        # 尝试获取命令行参数\n",
    "        import argparse\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--host\", default=\"0.0.0.0\", help=\"Host to bind to\")\n",
    "        parser.add_argument(\"--port\", type=int, default=7860, help=\"Port to bind to\")\n",
    "        parser.add_argument(\"--share\", action=\"store_true\", help=\"Enable sharing\")\n",
    "        args = parser.parse_args()\n",
    "        launch_kwargs = {\n",
    "            \"server_name\": args.host,\n",
    "            \"server_port\": args.port,\n",
    "            \"share\": args.share\n",
    "        }\n",
    "    except:\n",
    "        # 在notebook中运行时使用默认值\n",
    "        launch_kwargs = {\n",
    "            \"server_name\": \"0.0.0.0\",\n",
    "            \"share\": False,\n",
    "            \"debug\": True\n",
    "        }\n",
    "\n",
    "    ssl_cert = get_file_path(\"localhost+1.pem\", current_dir=current_dir)\n",
    "    ssl_key = get_file_path(\"localhost+1-key.pem\", current_dir=current_dir)\n",
    "\n",
    "    if os.path.exists(ssl_cert) and os.path.exists(ssl_key):\n",
    "        launch_kwargs.update({\n",
    "            \"ssl_certfile\": ssl_cert,\n",
    "            \"ssl_keyfile\": ssl_key\n",
    "        })\n",
    "\n",
    "    # 启动应用\n",
    "    demo.launch(**launch_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 1. 导入依赖 =====\n",
    "# 标准库导入\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# ===== 2. 初始化配置 =====\n",
    "# 获取当前文件所在目录的绝对路径\n",
    "if \"__file__\" in globals():\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir, \"..\"))\n",
    "else:\n",
    "    # 在 Jupyter Notebook 环境中\n",
    "    current_dir = os.getcwd()\n",
    "    current_dir = os.path.join(current_dir, \"..\")\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir))\n",
    "\n",
    "current_dir = os.path.normpath(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from Module.Components.config import Settings, load_prompt_file\n",
    "from Module.Common.scripts.llm.gemini_sdk import types, get_safety_settings\n",
    "from google import genai\n",
    "\n",
    "settings = Settings(current_dir=current_dir)\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv(os.path.join(current_dir, \".env\"))\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = genai.Client(api_key=api_key)\n",
    "\n",
    "\n",
    "model_name=\"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "# 创建分析器实例\n",
    "mode = \"simple\"\n",
    "\n",
    "if mode == \"extra\":\n",
    "    system_role = settings.config.get('extra_value_evaluation', {}).get('system_role')\n",
    "    new_schema = settings.config.get('extra_value_evaluation', {}).get('schema')\n",
    "elif mode == \"state\":\n",
    "    system_role = settings.state_system_prompt\n",
    "    new_schema = settings.response_schema\n",
    "elif mode == \"simple\":\n",
    "    system_role = load_prompt_file(\"system_role_trainer.md\", current_dir=current_dir)\n",
    "    system_role = \"你是一个睿智的吟游诗人\"\n",
    "    new_schema = None\n",
    "\n",
    "t1=get_safety_settings()\n",
    "t1[4].threshold=\"BLOCK_ONLY_HIGH\"\n",
    "# t1\n",
    "\n",
    "chat = gemini_client.chats.create(model=model_name,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_role,\n",
    "        response_mime_type=\"application/json\" if new_schema else \"text/plain\",\n",
    "        response_schema=new_schema,\n",
    "        temperature=0.7,\n",
    "        safety_settings=t1\n",
    "    ),)\n",
    "\n",
    "context=\"\"\"\n",
    "hello\n",
    "\"\"\"\n",
    "\n",
    "message_list=[\"\"\"\n",
    "为了方便阅读，我拆分排版一下。\n",
    "这是一开始的初始提示词，由<>包括：\n",
    "<初始提示词开始>\n",
    "\"\"\",settings.begin,\n",
    "\"\"\"\n",
    "<初始提示词结束>\n",
    "这是要分析的内容\n",
    "\"\"\"]\n",
    "# \"\"\",context]\n",
    "message=\"\\n\".join(message_list)\n",
    "\n",
    "message=\"你好呀\"\n",
    "\n",
    "response = chat.send_message(message)\n",
    "\n",
    "print(api_key)\n",
    "\n",
    "display(Markdown(response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05295818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from playsound import playsound  # 用于播放音频\n",
    "\n",
    "# 配置参数（替换为你的实际参数）\n",
    "COZE_API_BASE = \"https://api.coze.cn\"\n",
    "BOT_ID = \"7316745484305989638\"  # 替换为你的 Bot ID\n",
    "ACCESS_TOKEN = \"pat_mmmXVkHLMwTSqaoypfFyd213faLOV1MAq7rzNNRFOMnhW0DpGa4H9pWZzGPS4uwM\"  # 替换为你的访问令牌\n",
    "VOICE_ID = \"peach\"  # 中文女声音色\n",
    "\n",
    "def coze_tts(text: str, output_file: str = \"output.mp3\") -> bool:\n",
    "    \"\"\"\n",
    "    调用 Coze TTS 生成语音\n",
    "    :param text: 需要合成的文本\n",
    "    :param output_file: 输出音频文件路径（支持 .mp3/.wav）\n",
    "    :return: 是否成功\n",
    "    \"\"\"\n",
    "    url = f\"{COZE_API_BASE}/open_api/v2/tts\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"bot_id\": BOT_ID,\n",
    "        \"text\": text,\n",
    "        \"voice_id\": VOICE_ID,\n",
    "        \"model\": \"general\",  # 默认模型\n",
    "        \"format\": \"mp3\"  # 可选 mp3/wav\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # 检查 HTTP 错误\n",
    "\n",
    "        # 保存音频文件\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求失败: {e}\")\n",
    "        return False\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"你好，欢迎使用 Coze 语音合成服务！\"\n",
    "\n",
    "    # 生成语音文件\n",
    "    if coze_tts(input_text, \"speech.mp3\"):\n",
    "        print(\"语音生成成功，正在播放...\")\n",
    "        # 播放音频（需安装 playsound 库）\n",
    "        playsound(\"speech.mp3\")\n",
    "    else:\n",
    "        print(\"语音生成失败\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aecbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Audio\n",
    "\n",
    "def local_tts(text: str, speaker: str = \"步非烟\", instruct: str = \"性感诱惑的\", output_file: str = \"output.mp3\") -> bool:\n",
    "    \"\"\"\n",
    "    调用本地 TTS 服务生成语音\n",
    "    :param text: 需要合成的文本\n",
    "    :param speaker: 说话人\n",
    "    :param instruct: 语气指令\n",
    "    :param output_file: 输出音频文件路径\n",
    "    :return: 是否成功\n",
    "    \"\"\"\n",
    "    url = f\"http://localhost:9880/\"\n",
    "    params = {\n",
    "        \"text\": text,\n",
    "        \"speaker\": speaker,\n",
    "        \"instruct\": instruct\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # 检查 HTTP 错误\n",
    "\n",
    "        # 保存音频文件\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求失败: {e}\")\n",
    "        return False\n",
    "\n",
    "input_text = \"\"\"\n",
    "hello\n",
    "\"\"\"\n",
    "local_tts(input_text)\n",
    "Audio(\"output.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11180c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "from IPython.display import Audio\n",
    "\n",
    "voice_language=\"zh-CN\"\n",
    "# voice_language=\"zh-TW\"\n",
    "voice_name=\"HsiaoYuNeural\"\n",
    "voice_name=\"XiaoxiaoNeural\"\n",
    "\n",
    "voice=f\"{voice_language}-{voice_name}\"\n",
    "\n",
    "async def tts_edge(text):\n",
    "    communicate = edge_tts.Communicate(text, voice=voice)\n",
    "    await communicate.save(\"output1.mp3\")\n",
    "    return \"output1.mp3\"\n",
    "\n",
    "# 生成并播放音频\n",
    "text=\"\"\"\n",
    "hello\n",
    "\"\"\"\n",
    "audio_path = await tts_edge(text)\n",
    "Audio(audio_path, autoplay=True)  # 自动播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(text):\n",
    "    # Split text into chunks based on user: and assistant: markers\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_speaker = None\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.startswith('user:'):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_speaker, current_chunk.strip()))\n",
    "            current_speaker = 'user'\n",
    "            current_chunk = line[5:] # Remove 'user:'\n",
    "        elif line.startswith('assistant:'):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_speaker, current_chunk.strip()))\n",
    "            current_speaker = 'assistant'\n",
    "            current_chunk = line[10:] # Remove 'assistant:'\n",
    "        else:\n",
    "            current_chunk += '\\n' + line\n",
    "\n",
    "    # Add final chunk\n",
    "    if current_chunk:\n",
    "        chunks.append((current_speaker, current_chunk.strip()))\n",
    "\n",
    "    # Extract only user messages\n",
    "    return chunks\n",
    "\n",
    "with open(os.path.join(current_dir, \"local_setting/story.md\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    story_content = f.read()\n",
    "\n",
    "user_messages = [chunk[1] for chunk in chunk(story_content) if chunk[0] == 'user']\n",
    "user_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b39c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_talk = \"\"\"\n",
    "很棒，继续吧！\n",
    "\"\"\"\n",
    "result = chat.send_message(new_talk)\n",
    "display(Markdown(result.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66cb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd180e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"What is your name?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd352a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CountryInfo(BaseModel):\n",
    "    name: str\n",
    "    population: int\n",
    "    capital: str\n",
    "    continent: str\n",
    "    gdp: int\n",
    "    official_language: str\n",
    "    total_area_sq_mi: int\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"Give me information for the United States.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=CountryInfo,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b35cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"Tell me a story in 300 words.\"\n",
    "):\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for response in client.aio.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"Tell me a story in 300 words.\"\n",
    "):\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.embed_content(\n",
    "    model=\"text-embedding-004\",\n",
    "    contents=\"What is your name?\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0beed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Image\n",
    "image_prompt =\"\"\"\n",
    "1. Top: A white lace splicing long-sleeved dress. It reaches the knees, with a high neckline design that outlines a slender and elegant neckline. Lace and white asylum are in line with the freshness and innocence of girls, but also reveal a hint of sexiness.\n",
    "2. Skirt: Outside choose a white lace peplum dress, with a circle of lace peplum decoration at the knees, which looks romantic and lovely. Inside is a black gauze suspender skirt, vaguely showing tight curves and stocking edges. This contrasting design makes it difficult to grasp the truth inside.\n",
    "3. Underwear: A French lace bustier that perfectly outlines the full breasts and half conceals them. Seemingly harmless on the surface, it is extremely sexy in reality, forming a sharp contrast with the outer jacket.\n",
    "4. Shoes: A pair of white thick-soled lace-up sandals, as lovely as a girl. Inside are a pair of black stockings and fine high-heeled ankle locks that can be vaguely seen under the skirt from time to time, proclaiming the real unrestrained side.\n",
    "5. Hairstyle and makeup: Innocent medium-length shaggy hair and light makeup. But the lips are stained with extremely red lipstick, which is fascinating. This contrast becomes an important breakthrough in the overall styling, allowing people to catch a glimpse of the real look at a glance.\n",
    "\n",
    "On the surface, this styling still reflects the innocent and lovely girl's sense. But in the details, it reveals traces of unrestrained and sexy everywhere, making it impossible to ignore the existence of the real look. It creates a strong contrast between the two styles, but also integrates them into one, making it difficult for people to clearly judge for a while. This is precisely the effect and highest realm that sissy bimbo has always pursued.\n",
    "This styling makes her an seemingly innocent but extremely charming existence. She walks between the inside and outside, switching back and forth between two completely different worlds, fascinating everyone but also incomprehensible. This is what she pursues, and it is also the state she most desires to achieve in her life. She is an indefinable woman, a perfect representative who truly achieves inner and outer cultivation.\n",
    "\"\"\"\n",
    "\n",
    "response1 = client.models.generate_image(\n",
    "    model=\"imagen-3.0-generate-001\",\n",
    "    prompt=image_prompt,\n",
    "    config=types.GenerateImageConfig(\n",
    "        # negative_prompt=\"human\",\n",
    "        number_of_images=1,\n",
    "        include_rai_reason=True,\n",
    "        output_mime_type=\"image/jpeg\",\n",
    "        person_generation=\"ALLOW_ALL\",\n",
    "        safety_filter_level=\"BLOCK_NONE\"\n",
    "    ),\n",
    ")\n",
    "response1.generated_images[0].image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\n",
    "\"\"\"\n",
    "故事先到这里吧。接下来我需要你协助做另一个事情。\n",
    "我计划把这个创作过程修改成一个由llm驱动的游戏世界，故事的大纲仍然如此，但职业和发生的事情每次都是随机生成的。\n",
    "此外，在文字冒险的过程中，玩家在每个阶段都需要经过最多三四步的操作，然后触发这个阶段的标志性事件，然后再过度到下一个阶段。\n",
    "\n",
    "为了实现这个效果，我需要先完成各个层级的系统提示词。除了参考模板里的字段和特殊的专有名词，其他就都用中文。\n",
    "请你结合我给你的模板的思路，和我们发生的故事、大纲以及要随机的部分，精心设计一个属于这个故事的数据结构，并帮我完成这些系统提示词\n",
    "让我们一步一步来，先沟通清楚推荐的数据结构。\n",
    "\n",
    "参考模板：\n",
    "<system_role_prompt>\n",
    "Your job is to help create interesting fantasy worlds that \\\n",
    "players would love to play in.\n",
    "Instructions:\n",
    "- Only generate in plain text without formatting.\n",
    "- Use simple clear language without being flowery.\n",
    "- You must stay below 3-5 sentences for each description.\n",
    "\n",
    "<world_prompt>\n",
    "Generate a creative description for a unique fantasy world with an\n",
    "interesting concept around cities build on the backs of massive beasts.\n",
    "\n",
    "Output content in the form:\n",
    "World Name: <WORLD NAME>\n",
    "World Description: <WORLD DESCRIPTION>\n",
    "\n",
    "World Name:\n",
    "\n",
    "<kingdom_prompt>\n",
    "Create 3 different kingdoms for a fantasy world.\n",
    "For each kingdom generate a description based on the world it's in. \\\n",
    "Describe important leaders, cultures, history of the kingdom.\\\n",
    "\n",
    "Output content in the form:\n",
    "Kingdom 1 Name: <KINGDOM NAME>\n",
    "Kingdom 1 Description: <KINGDOM DESCRIPTION>\n",
    "Kingdom 2 Name: <KINGDOM NAME>\n",
    "Kingdom 2 Description: <KINGDOM DESCRIPTION>\n",
    "Kingdom 3 Name: <KINGDOM NAME>\n",
    "Kingdom 3 Description: <KINGDOM DESCRIPTION>\n",
    "\n",
    "World Name: {world['name']}\n",
    "World Description: {world['description']}\n",
    "\n",
    "Kingdom 1\n",
    "\n",
    "def get_town_prompt(world, kingdom):\n",
    "    return f\"\n",
    "    Create 3 different towns for a fantasy kingdom abd world. \\\n",
    "    Describe the region it's in, important places of the town, \\\n",
    "    and interesting history about it. \\\n",
    "\n",
    "    Output content in the form:\n",
    "    Town 1 Name: <TOWN NAME>\n",
    "    Town 1 Description: <TOWN DESCRIPTION>\n",
    "    Town 2 Name: <TOWN NAME>\n",
    "    Town 2 Description: <TOWN DESCRIPTION>\n",
    "    Town 3 Name: <TOWN NAME>\n",
    "    Town 3 Description: <TOWN DESCRIPTION>\n",
    "\n",
    "    World Name: {world['name']}\n",
    "    World Description: {world['description']}\n",
    "\n",
    "    Kingdom Name: {kingdom['name']}\n",
    "    Kingdom Description {kingdom['description']}\n",
    "\n",
    "    Town 1 Name:\"\n",
    "\n",
    "def get_npc_prompt(world, kingdom, town):\n",
    "    return f\"\n",
    "    Create 3 different characters based on the world, kingdom \\\n",
    "    and town they're in. Describe the character's appearance and \\\n",
    "    profession, as well as their deeper pains and desires. \\\n",
    "\n",
    "    Output content in the form:\n",
    "    Character 1 Name: <CHARACTER NAME>\n",
    "    Character 1 Description: <CHARACTER DESCRIPTION>\n",
    "    Character 2 Name: <CHARACTER NAME>\n",
    "    Character 2 Description: <CHARACTER DESCRIPTION>\n",
    "    Character 3 Name: <CHARACTER NAME>\n",
    "    Character 3 Description: <CHARACTER DESCRIPTION>\n",
    "\n",
    "    World Name: {world['name']}\n",
    "    World Description: {world['description']}\n",
    "\n",
    "    Kingdom Name: {kingdom['name']}\n",
    "    Kingdom Description: {kingdom['description']}\n",
    "\n",
    "    Town Name: {town['name']}\n",
    "    Town Description: {town['description']}\n",
    "\n",
    "    Character 1 Name:\"\n",
    "\n",
    "<item manager>\n",
    "You are an AI Game Assistant. \\\n",
    "Your job is to detect changes to a player's \\\n",
    "inventory based on the most recent story and game state.\n",
    "If a player picks up, or gains an item add it to the inventory \\\n",
    "with a positive change_amount.\n",
    "If a player loses an item remove it from their inventory \\\n",
    "with a negative change_amount.\n",
    "Given a player name, inventory and story, return a list of json update\n",
    "of the player's inventory in the following form.\n",
    "Only take items that it's clear the player (you) lost.\n",
    "Only give items that it's clear the player gained.\n",
    "Don't make any other item updates.\n",
    "If no items were changed return {\"itemUpdates\": []}\n",
    "and nothing else.\n",
    "\n",
    "Response must be in Valid JSON\n",
    "Don't add items that were already added in the inventory\n",
    "\n",
    "Inventory Updates:\n",
    "{\n",
    "    \"itemUpdates\": [\n",
    "        {\"name\": <ITEM NAME>,\n",
    "        \"change_amount\": <CHANGE AMOUNT>}...\n",
    "    ]\n",
    "}\n",
    "\n",
    "\"\"\")\n",
    "display(Markdown(response.text))\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WorkSpace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测 chat_rag.py 文件\n",
    "file_path = \"../app.py\"\n",
    "# file_path = \"../Module/Components/state_manager.py\"\n",
    "# file_path = \"../Module/Components/config.py\"\n",
    "!flake8 {file_path} --max-line-length=240\n",
    "!pylint {file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb30623",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ..\\app_temp.py\n",
    "# pylint: disable=import-error  # Project structure requires dynamic path handling\n",
    "# pylint: disable=wrong-import-position  # Path setup must come before local imports\n",
    "\"\"\"应用入口文件\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "# ===== 2. 初始化配置 =====\n",
    "# 获取当前文件所在目录的绝对路径\n",
    "if \"__file__\" in globals():\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir, \"..\"))\n",
    "else:\n",
    "    # 在 Jupyter Notebook 环境中\n",
    "    current_dir = os.getcwd()\n",
    "    current_dir = os.path.join(current_dir, \"..\")\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir))\n",
    "\n",
    "current_dir = os.path.normpath(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from Module.AppCore.app_manager import AppManager\n",
    "from Module.AppCore.ui_manager import UIManager\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 在程序启动前添加以下代码\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "    # 初始化应用管理器\n",
    "    app_manager = AppManager(current_dir)\n",
    "\n",
    "    # 初始化UI管理器\n",
    "    ui_manager = UIManager(app_manager)\n",
    "\n",
    "    # 启动应用\n",
    "    ui_manager.launch()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 1. 导入依赖 =====\n",
    "# 标准库导入\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# ===== 2. 初始化配置 =====\n",
    "# 获取当前文件所在目录的绝对路径\n",
    "if \"__file__\" in globals():\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir, \"..\"))\n",
    "else:\n",
    "    # 在 Jupyter Notebook 环境中\n",
    "    current_dir = os.getcwd()\n",
    "    current_dir = os.path.join(current_dir, \"..\")\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir))\n",
    "\n",
    "current_dir = os.path.normpath(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from Module.Components.config import Settings, load_prompt_file\n",
    "from Module.Common.scripts.llm.gemini_sdk import types, get_safety_settings, get_content_config\n",
    "from google import genai\n",
    "\n",
    "settings = Settings(current_dir=current_dir)\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv(os.path.join(current_dir, \".env\"))\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = genai.Client(api_key=api_key)\n",
    "\n",
    "\n",
    "model_name=\"gemini-2.0-flash-exp\"\n",
    "# 创建分析器实例\n",
    "mode = \"simple\"\n",
    "\n",
    "if mode == \"extra\":\n",
    "    system_role = settings.config.get('extra_value_evaluation', {}).get('system_role')\n",
    "    new_schema = settings.config.get('extra_value_evaluation', {}).get('schema')\n",
    "elif mode == \"state\":\n",
    "    system_role = settings.state_system_prompt\n",
    "    new_schema = settings.response_schema\n",
    "elif mode == \"simple\":\n",
    "    system_role = load_prompt_file(\"system_role.md\", current_dir=current_dir)\n",
    "    # system_role = \"你是一个睿智的吟游诗人\"\n",
    "    new_schema = None\n",
    "\n",
    "t1=get_safety_settings()\n",
    "# t1[4].threshold=\"BLOCK_ONLY_HIGH\"\n",
    "# t1\n",
    "config=types.GenerateContentConfig(\n",
    "        system_instruction=system_role,\n",
    "        response_mime_type=\"application/json\" if new_schema else \"text/plain\",\n",
    "        response_schema=new_schema,\n",
    "        temperature=0.7,\n",
    "        safety_settings=t1\n",
    "    )\n",
    "\n",
    "chat = gemini_client.chats.create(model=model_name,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "context=\"\"\"\n",
    "hello\n",
    "\"\"\"\n",
    "\n",
    "message_list=[\"\"\"\n",
    "为了方便阅读，我拆分排版一下。\n",
    "这是一开始的初始提示词，由<>包括：\n",
    "<初始提示词开始>\n",
    "\"\"\",settings.begin,\n",
    "\"\"\"\n",
    "<初始提示词结束>\n",
    "这是要分析的内容\n",
    "\"\"\"]\n",
    "# \"\"\",context]\n",
    "message=\"\\n\".join(message_list)\n",
    "\n",
    "message=\"你好呀\"\n",
    "\n",
    "message=\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# message=\"你好呀\"\n",
    "contents = get_content_config(message, system_role)\n",
    "contents=message\n",
    "\n",
    "# response = chat.send_message(message)\n",
    "for chunk in gemini_client.models.generate_content_stream(\n",
    "    model=model_name,\n",
    "    contents=contents,\n",
    "    config=config\n",
    "):\n",
    "    print(chunk)\n",
    "# print(api_key)\n",
    "\n",
    "# display(Markdown(response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ddae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05295818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from playsound import playsound  # 用于播放音频\n",
    "\n",
    "load_dotenv(os.path.join(current_dir, \".env\"))\n",
    "ACCESS_TOKEN = os.getenv(\"COZE_API_KEY\")\n",
    "\n",
    "# 配置参数（替换为你的实际参数）\n",
    "COZE_API_BASE = \"https://api.coze.cn\"\n",
    "BOT_ID = \"7316745484305989638\"  # 替换为你的 Bot ID\n",
    "VOICE_ID = \"peach\"  # 中文女声音色\n",
    "\n",
    "def coze_tts(text: str, output_file: str = \"output.mp3\") -> bool:\n",
    "    \"\"\"\n",
    "    调用 Coze TTS 生成语音\n",
    "    :param text: 需要合成的文本\n",
    "    :param output_file: 输出音频文件路径（支持 .mp3/.wav）\n",
    "    :return: 是否成功\n",
    "    \"\"\"\n",
    "    url = f\"{COZE_API_BASE}/open_api/v2/tts\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"bot_id\": BOT_ID,\n",
    "        \"text\": text,\n",
    "        \"voice_id\": VOICE_ID,\n",
    "        \"model\": \"general\",  # 默认模型\n",
    "        \"format\": \"mp3\"  # 可选 mp3/wav\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # 检查 HTTP 错误\n",
    "\n",
    "        # 保存音频文件\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求失败: {e}\")\n",
    "        return False\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"你好，欢迎使用 Coze 语音合成服务！\"\n",
    "\n",
    "    # 生成语音文件\n",
    "    if coze_tts(input_text, \"speech.mp3\"):\n",
    "        print(\"语音生成成功，正在播放...\")\n",
    "        # 播放音频（需安装 playsound 库）\n",
    "        playsound(\"speech.mp3\")\n",
    "    else:\n",
    "        print(\"语音生成失败\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aecbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Audio\n",
    "\n",
    "def local_tts(text: str, speaker: str = \"步非烟\", instruct: str = \"性感诱惑的\", output_file: str = \"output.mp3\") -> bool:\n",
    "    \"\"\"\n",
    "    调用本地 TTS 服务生成语音\n",
    "    :param text: 需要合成的文本\n",
    "    :param speaker: 说话人\n",
    "    :param instruct: 语气指令\n",
    "    :param output_file: 输出音频文件路径\n",
    "    :return: 是否成功\n",
    "    \"\"\"\n",
    "    url = f\"http://localhost:9880/\"\n",
    "    params = {\n",
    "        \"text\": text,\n",
    "        \"speaker\": speaker,\n",
    "        \"instruct\": instruct\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # 检查 HTTP 错误\n",
    "\n",
    "        # 保存音频文件\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求失败: {e}\")\n",
    "        return False\n",
    "\n",
    "input_text = \"\"\"\n",
    "hello\n",
    "\"\"\"\n",
    "local_tts(input_text)\n",
    "Audio(\"output.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11180c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "from IPython.display import Audio\n",
    "\n",
    "voice_language=\"zh-CN\"\n",
    "# voice_language=\"zh-TW\"\n",
    "voice_name=\"HsiaoYuNeural\"\n",
    "voice_name=\"XiaoxiaoNeural\"\n",
    "\n",
    "voice=f\"{voice_language}-{voice_name}\"\n",
    "\n",
    "async def tts_edge(text):\n",
    "    communicate = edge_tts.Communicate(text, voice=voice)\n",
    "    await communicate.save(\"output1.mp3\")\n",
    "    return \"output1.mp3\"\n",
    "\n",
    "# 生成并播放音频\n",
    "text=\"\"\"\n",
    "hello\n",
    "\"\"\"\n",
    "audio_path = await tts_edge(text)\n",
    "Audio(audio_path, autoplay=True)  # 自动播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(text):\n",
    "    # Split text into chunks based on user: and assistant: markers\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_speaker = None\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.startswith('user:'):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_speaker, current_chunk.strip()))\n",
    "            current_speaker = 'user'\n",
    "            current_chunk = line[5:] # Remove 'user:'\n",
    "        elif line.startswith('assistant:'):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_speaker, current_chunk.strip()))\n",
    "            current_speaker = 'assistant'\n",
    "            current_chunk = line[10:] # Remove 'assistant:'\n",
    "        else:\n",
    "            current_chunk += '\\n' + line\n",
    "\n",
    "    # Add final chunk\n",
    "    if current_chunk:\n",
    "        chunks.append((current_speaker, current_chunk.strip()))\n",
    "\n",
    "    # Extract only user messages\n",
    "    return chunks\n",
    "\n",
    "with open(os.path.join(current_dir, \"local_setting/story.md\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    story_content = f.read()\n",
    "\n",
    "user_messages = [chunk[1] for chunk in chunk(story_content) if chunk[0] == 'user']\n",
    "user_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b39c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_talk = \"\"\"\n",
    "很棒，继续吧！\n",
    "\"\"\"\n",
    "result = chat.send_message(new_talk)\n",
    "display(Markdown(result.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66cb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd180e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"What is your name?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd352a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CountryInfo(BaseModel):\n",
    "    name: str\n",
    "    population: int\n",
    "    capital: str\n",
    "    continent: str\n",
    "    gdp: int\n",
    "    official_language: str\n",
    "    total_area_sq_mi: int\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"Give me information for the United States.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=CountryInfo,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b35cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"Tell me a story in 300 words.\"\n",
    "):\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for response in client.aio.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"Tell me a story in 300 words.\"\n",
    "):\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.embed_content(\n",
    "    model=\"text-embedding-004\",\n",
    "    contents=\"What is your name?\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0beed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Image\n",
    "image_prompt =\"\"\"\n",
    "1. Top: A white lace splicing long-sleeved dress. It reaches the knees, with a high neckline design that outlines a slender and elegant neckline. Lace and white asylum are in line with the freshness and innocence of girls, but also reveal a hint of sexiness.\n",
    "2. Skirt: Outside choose a white lace peplum dress, with a circle of lace peplum decoration at the knees, which looks romantic and lovely. Inside is a black gauze suspender skirt, vaguely showing tight curves and stocking edges. This contrasting design makes it difficult to grasp the truth inside.\n",
    "3. Underwear: A French lace bustier that perfectly outlines the full breasts and half conceals them. Seemingly harmless on the surface, it is extremely sexy in reality, forming a sharp contrast with the outer jacket.\n",
    "4. Shoes: A pair of white thick-soled lace-up sandals, as lovely as a girl. Inside are a pair of black stockings and fine high-heeled ankle locks that can be vaguely seen under the skirt from time to time, proclaiming the real unrestrained side.\n",
    "5. Hairstyle and makeup: Innocent medium-length shaggy hair and light makeup. But the lips are stained with extremely red lipstick, which is fascinating. This contrast becomes an important breakthrough in the overall styling, allowing people to catch a glimpse of the real look at a glance.\n",
    "\n",
    "On the surface, this styling still reflects the innocent and lovely girl's sense. But in the details, it reveals traces of unrestrained and sexy everywhere, making it impossible to ignore the existence of the real look. It creates a strong contrast between the two styles, but also integrates them into one, making it difficult for people to clearly judge for a while. This is precisely the effect and highest realm that sissy bimbo has always pursued.\n",
    "This styling makes her an seemingly innocent but extremely charming existence. She walks between the inside and outside, switching back and forth between two completely different worlds, fascinating everyone but also incomprehensible. This is what she pursues, and it is also the state she most desires to achieve in her life. She is an indefinable woman, a perfect representative who truly achieves inner and outer cultivation.\n",
    "\"\"\"\n",
    "\n",
    "response1 = client.models.generate_image(\n",
    "    model=\"imagen-3.0-generate-001\",\n",
    "    prompt=image_prompt,\n",
    "    config=types.GenerateImageConfig(\n",
    "        # negative_prompt=\"human\",\n",
    "        number_of_images=1,\n",
    "        include_rai_reason=True,\n",
    "        output_mime_type=\"image/jpeg\",\n",
    "        person_generation=\"ALLOW_ALL\",\n",
    "        safety_filter_level=\"BLOCK_NONE\"\n",
    "    ),\n",
    ")\n",
    "response1.generated_images[0].image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\n",
    "\"\"\"\n",
    "故事先到这里吧。接下来我需要你协助做另一个事情。\n",
    "我计划把这个创作过程修改成一个由llm驱动的游戏世界，故事的大纲仍然如此，但职业和发生的事情每次都是随机生成的。\n",
    "此外，在文字冒险的过程中，玩家在每个阶段都需要经过最多三四步的操作，然后触发这个阶段的标志性事件，然后再过度到下一个阶段。\n",
    "\n",
    "为了实现这个效果，我需要先完成各个层级的系统提示词。除了参考模板里的字段和特殊的专有名词，其他就都用中文。\n",
    "请你结合我给你的模板的思路，和我们发生的故事、大纲以及要随机的部分，精心设计一个属于这个故事的数据结构，并帮我完成这些系统提示词\n",
    "让我们一步一步来，先沟通清楚推荐的数据结构。\n",
    "\n",
    "参考模板：\n",
    "<system_role_prompt>\n",
    "Your job is to help create interesting fantasy worlds that \\\n",
    "players would love to play in.\n",
    "Instructions:\n",
    "- Only generate in plain text without formatting.\n",
    "- Use simple clear language without being flowery.\n",
    "- You must stay below 3-5 sentences for each description.\n",
    "\n",
    "<world_prompt>\n",
    "Generate a creative description for a unique fantasy world with an\n",
    "interesting concept around cities build on the backs of massive beasts.\n",
    "\n",
    "Output content in the form:\n",
    "World Name: <WORLD NAME>\n",
    "World Description: <WORLD DESCRIPTION>\n",
    "\n",
    "World Name:\n",
    "\n",
    "<kingdom_prompt>\n",
    "Create 3 different kingdoms for a fantasy world.\n",
    "For each kingdom generate a description based on the world it's in. \\\n",
    "Describe important leaders, cultures, history of the kingdom.\\\n",
    "\n",
    "Output content in the form:\n",
    "Kingdom 1 Name: <KINGDOM NAME>\n",
    "Kingdom 1 Description: <KINGDOM DESCRIPTION>\n",
    "Kingdom 2 Name: <KINGDOM NAME>\n",
    "Kingdom 2 Description: <KINGDOM DESCRIPTION>\n",
    "Kingdom 3 Name: <KINGDOM NAME>\n",
    "Kingdom 3 Description: <KINGDOM DESCRIPTION>\n",
    "\n",
    "World Name: {world['name']}\n",
    "World Description: {world['description']}\n",
    "\n",
    "Kingdom 1\n",
    "\n",
    "def get_town_prompt(world, kingdom):\n",
    "    return f\"\n",
    "    Create 3 different towns for a fantasy kingdom abd world. \\\n",
    "    Describe the region it's in, important places of the town, \\\n",
    "    and interesting history about it. \\\n",
    "\n",
    "    Output content in the form:\n",
    "    Town 1 Name: <TOWN NAME>\n",
    "    Town 1 Description: <TOWN DESCRIPTION>\n",
    "    Town 2 Name: <TOWN NAME>\n",
    "    Town 2 Description: <TOWN DESCRIPTION>\n",
    "    Town 3 Name: <TOWN NAME>\n",
    "    Town 3 Description: <TOWN DESCRIPTION>\n",
    "\n",
    "    World Name: {world['name']}\n",
    "    World Description: {world['description']}\n",
    "\n",
    "    Kingdom Name: {kingdom['name']}\n",
    "    Kingdom Description {kingdom['description']}\n",
    "\n",
    "    Town 1 Name:\"\n",
    "\n",
    "def get_npc_prompt(world, kingdom, town):\n",
    "    return f\"\n",
    "    Create 3 different characters based on the world, kingdom \\\n",
    "    and town they're in. Describe the character's appearance and \\\n",
    "    profession, as well as their deeper pains and desires. \\\n",
    "\n",
    "    Output content in the form:\n",
    "    Character 1 Name: <CHARACTER NAME>\n",
    "    Character 1 Description: <CHARACTER DESCRIPTION>\n",
    "    Character 2 Name: <CHARACTER NAME>\n",
    "    Character 2 Description: <CHARACTER DESCRIPTION>\n",
    "    Character 3 Name: <CHARACTER NAME>\n",
    "    Character 3 Description: <CHARACTER DESCRIPTION>\n",
    "\n",
    "    World Name: {world['name']}\n",
    "    World Description: {world['description']}\n",
    "\n",
    "    Kingdom Name: {kingdom['name']}\n",
    "    Kingdom Description: {kingdom['description']}\n",
    "\n",
    "    Town Name: {town['name']}\n",
    "    Town Description: {town['description']}\n",
    "\n",
    "    Character 1 Name:\"\n",
    "\n",
    "<item manager>\n",
    "You are an AI Game Assistant. \\\n",
    "Your job is to detect changes to a player's \\\n",
    "inventory based on the most recent story and game state.\n",
    "If a player picks up, or gains an item add it to the inventory \\\n",
    "with a positive change_amount.\n",
    "If a player loses an item remove it from their inventory \\\n",
    "with a negative change_amount.\n",
    "Given a player name, inventory and story, return a list of json update\n",
    "of the player's inventory in the following form.\n",
    "Only take items that it's clear the player (you) lost.\n",
    "Only give items that it's clear the player gained.\n",
    "Don't make any other item updates.\n",
    "If no items were changed return {\"itemUpdates\": []}\n",
    "and nothing else.\n",
    "\n",
    "Response must be in Valid JSON\n",
    "Don't add items that were already added in the inventory\n",
    "\n",
    "Inventory Updates:\n",
    "{\n",
    "    \"itemUpdates\": [\n",
    "        {\"name\": <ITEM NAME>,\n",
    "        \"change_amount\": <CHANGE AMOUNT>}...\n",
    "    ]\n",
    "}\n",
    "\n",
    "\"\"\")\n",
    "display(Markdown(response.text))\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WorkSpace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

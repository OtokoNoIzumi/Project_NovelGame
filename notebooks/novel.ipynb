{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11bb2797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------\n",
      "Your code has been rated at 10.00/10 (previous run: 10.00/10, +0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 检测 chat_rag.py 文件\n",
    "# file_path = \"../app.py\"\n",
    "# file_path = \"../Module/Components/state_manager.py\"\n",
    "# file_path = \"../Module/Components/config.py\"\n",
    "!flake8 {file_path} --max-line-length=240\n",
    "!pylint {file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bb30623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ..\\app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ..\\app.py\n",
    "# pylint: disable=import-error  # Project structure requires dynamic path handling\n",
    "# pylint: disable=wrong-import-position  # Path setup must come before local imports\n",
    "\"\"\"\n",
    "For more information on `huggingface_hub` Inference API support\n",
    "please check the docs: https://huggingface.co/docs/huggingface_hub/v0.22.2/en/guides/inference\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import gradio as gr\n",
    "from google import genai\n",
    "# ===== 2. 初始化配置 =====\n",
    "# 获取当前文件所在目录的绝对路径\n",
    "if \"__file__\" in globals():\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir, \"..\"))\n",
    "else:\n",
    "    # 在 Jupyter Notebook 环境中\n",
    "    current_dir = os.getcwd()\n",
    "    current_dir = os.path.join(current_dir, \"..\")\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir))\n",
    "\n",
    "current_dir = os.path.normpath(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from Module.Components.config import get_file_path, Settings\n",
    "from Module.Components.state_manager import StateManager\n",
    "from Module.Common.scripts.llm.gemini_sdk import (\n",
    "    types,\n",
    "    get_safety_settings,\n",
    "    format_content,\n",
    "    get_content_config\n",
    ")\n",
    "from Module.Common.scripts.llm.utils.schema_response import ContentAnalyzer\n",
    "from Module.Common.scripts.common.debug_utils import log_and_print\n",
    "\n",
    "# 使用方式\n",
    "settings = Settings(current_dir=current_dir)\n",
    "\n",
    "gemini_client = genai.Client(api_key=settings.api_key)\n",
    "\n",
    "MODEL_NAME = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "\n",
    "def gemini_generate_with_schema(\n",
    "    client: Any,\n",
    "    input_text: str,\n",
    "    response_schema: Dict,\n",
    "    system_prompt: str = \"\"\n",
    ") -> Any:\n",
    "    \"\"\"使用Gemini生成带schema的响应\n",
    "\n",
    "    Args:\n",
    "        client: Gemini客户端实例\n",
    "        input_text: 输入文本\n",
    "        response_schema: 响应schema定义\n",
    "        system_prompt: 系统提示词\n",
    "\n",
    "    Returns:\n",
    "        生成的响应内容\n",
    "    \"\"\"\n",
    "    # log_and_print(f\"gemini_generate_with_schema: {input_text}\")\n",
    "    return client.models.generate_content(\n",
    "        model=MODEL_NAME,\n",
    "        contents=[format_content(\"user\", input_text)],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_prompt,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=response_schema,\n",
    "            safety_settings=get_safety_settings(),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def game_response_formatter(response: Any) -> Dict[str, Any]:\n",
    "    \"\"\"格式化游戏响应\n",
    "\n",
    "    Args:\n",
    "        response: 原始响应内容\n",
    "\n",
    "    Returns:\n",
    "        格式化后的响应字典\n",
    "    \"\"\"\n",
    "    log_and_print(\"game_response_formatter:\\n\", response.text)\n",
    "    updates = json.loads(response.text)\n",
    "\n",
    "    # Deduplicate character state updates by attribute\n",
    "    state_updates = updates.get('stateUpdates', [])\n",
    "    seen_attrs = {}\n",
    "\n",
    "    for i, update in enumerate(state_updates):\n",
    "        attr = update['attribute']\n",
    "        if attr in seen_attrs:\n",
    "\n",
    "            log_and_print(\"attribute_update_game_response_formatter:\\n\", attr)\n",
    "\n",
    "            extra_state_attribute = settings.config.get(\"extra_state_attributes\", [])[0]\n",
    "            prev_idx = seen_attrs[attr]\n",
    "            prev_update = state_updates[prev_idx]\n",
    "\n",
    "            # Compare extra_state if available\n",
    "            if extra_state_attribute in update and extra_state_attribute in prev_update:\n",
    "                if update[extra_state_attribute] > prev_update[extra_state_attribute]:\n",
    "                    state_updates[prev_idx] = update\n",
    "            # Otherwise keep the later update\n",
    "            else:\n",
    "                state_updates[prev_idx] = update\n",
    "\n",
    "            state_updates[i] = None\n",
    "        else:\n",
    "            seen_attrs[attr] = i\n",
    "\n",
    "    # Remove None entries\n",
    "    updates['stateUpdates'] = [u for u in state_updates if u is not None]\n",
    "\n",
    "    return {\n",
    "        'inventory': updates.get('itemUpdates', []),\n",
    "        'character_state': updates.get('stateUpdates', [])\n",
    "    }\n",
    "\n",
    "\n",
    "def game_context_formatter(current_data: Dict[str, Any], content: str) -> str:\n",
    "    \"\"\"格式化游戏上下文\n",
    "\n",
    "    Args:\n",
    "        current_data: 当前游戏数据\n",
    "        content: 内容文本\n",
    "\n",
    "    Returns:\n",
    "        格式化后的上下文字符串\n",
    "    \"\"\"\n",
    "    extra_state_attribute = settings.config.get(\"extra_state_attributes\", [])\n",
    "    extra_state_hint = \"\"\n",
    "    if extra_state_attribute:\n",
    "        extra_state_hint = (\n",
    "            f\"- 为了阅读顺畅，故事内容里不会明示出现下列属性{extra_state_attribute}的信息，\"\n",
    "            \"但请根据故事内容和状态初始值，分析出变化来；\"\n",
    "            f\"每个角色状态的变化，都必然伴随着{extra_state_attribute}的变化，在这个故事里，变化值都是在初始值的基础上增加\"\n",
    "        )\n",
    "    formatted_content = f\"\"\"\n",
    "请根据最近故事内容分析物品清单、角色状态的变化。\n",
    "\n",
    "这是一些可参考的规则：\n",
    "- 物品就用名称表述，如果描述太长，就概述到名称不超过10个汉字，每件东西都单独列成一条，除非是套装，\n",
    "- 基本上角色已经获得过的道具不会重复获得，除非特别说明又继续增加或更多了。\n",
    "- 角色状态只会包含下面状态列表里的项目。\n",
    "- 除了数据结构中的字段，其他都用中文回复。\n",
    "{extra_state_hint}\n",
    "\n",
    "当前状态\n",
    "<物品清单>\n",
    "{current_data.get('inventory', {})}\n",
    "</物品清单>\n",
    "\n",
    "<角色状态>\n",
    "{current_data.get('character_state', {})}\n",
    "</角色状态>\n",
    "\n",
    "<最近故事内容>\n",
    "{content}\n",
    "</最近故事内容>\n",
    "\"\"\"\n",
    "    log_and_print(\"game_context_formatter:\\n\", formatted_content)\n",
    "    return formatted_content\n",
    "\n",
    "\n",
    "# 创建分析器实例\n",
    "analyzer = ContentAnalyzer(\n",
    "    llm_client=gemini_client,\n",
    "    generate_func=gemini_generate_with_schema,\n",
    "    response_schema=settings.response_schema,\n",
    "    system_prompt=settings.state_system_prompt,\n",
    "    context_formatter=game_context_formatter,\n",
    "    response_formatter=game_response_formatter\n",
    ")\n",
    "\n",
    "\n",
    "def get_gradio_version() -> str:\n",
    "    \"\"\"获取Gradio版本号\n",
    "\n",
    "    Returns:\n",
    "        Gradio版本号字符串\n",
    "    \"\"\"\n",
    "    return gr.__version__\n",
    "\n",
    "\n",
    "def create_initial_state() -> Dict:\n",
    "    \"\"\"创建初始游戏状态\n",
    "\n",
    "    Returns:\n",
    "        包含初始状态的字典\n",
    "    \"\"\"\n",
    "    initial_state = {\n",
    "        \"gr_version\": get_gradio_version(),\n",
    "        \"story_chapter\": \"起因\",\n",
    "        \"story_chapter_stage\": 1,\n",
    "        \"inventory\": {},\n",
    "        \"character_state\": {}\n",
    "    }\n",
    "    # 深度拷贝确保完全隔离\n",
    "    for attr in settings.config[\"state_attributes\"]:\n",
    "        initial_state[\"character_state\"][attr] = {\n",
    "            \"state\": \"\",  # 主状态\n",
    "        }\n",
    "        # 添加额外属性\n",
    "        for extra_attr in settings.config.get(\"extra_state_attributes\", []):\n",
    "            initial_state[\"character_state\"][attr][extra_attr] = 0\n",
    "    return initial_state\n",
    "\n",
    "\n",
    "game_state = create_initial_state()\n",
    "\n",
    "state_manager = StateManager(create_initial_state(), settings.config)\n",
    "\n",
    "# 区分用于处理的历史记录和用于显示的历史记录\n",
    "# 使用字典来存储对话历史和当前ID\n",
    "chat_data = {\n",
    "    \"current_id\": 0,\n",
    "    \"history\": []  # 列表中存储对话记录字典，每条记录包含role、content、only_for_display和id属性\n",
    "}\n",
    "\n",
    "\n",
    "def detect_state_changes(game_state_dict: dict, story_output: str) -> Dict:\n",
    "    \"\"\"检测游戏状态变化\n",
    "\n",
    "    Args:\n",
    "        game_state_dict: 当前游戏状态字典\n",
    "        story_output: 故事输出文本\n",
    "\n",
    "    Returns:\n",
    "        状态更新信息\n",
    "    \"\"\"\n",
    "    updates = analyzer.analyze(game_state_dict, story_output)\n",
    "    return state_manager.apply_updates(updates)\n",
    "\n",
    "\n",
    "def _should_append_state() -> bool:\n",
    "    \"\"\"判断是否需要附加状态信息\"\"\"\n",
    "    return (\n",
    "        game_state[\"story_chapter_stage\"] > 1 or\n",
    "        game_state[\"story_chapter\"] != \"起因\" or\n",
    "        chat_data[\"current_id\"] > 1\n",
    "    )\n",
    "\n",
    "\n",
    "def _handle_special_messages(message: str, history: List[Tuple[str, str]], ignore_job: str) -> str:\n",
    "    \"\"\"处理特殊消息命令\"\"\"\n",
    "    if message == \"开始\" and not history:\n",
    "        begin_message = settings.begin\n",
    "        if settings.config[\"initial_state\"]:\n",
    "            begin_message += (\n",
    "                \"\\n请在应当确认随机内容的时机一并初始化状态和持有物品，状态属性清单如下：\" +\n",
    "                \"\\n\".join(settings.config[\"state_attributes\"])\n",
    "            )\n",
    "        return begin_message\n",
    "\n",
    "    if message == \"确认\" and len(history) == 2:\n",
    "        if '{explored_jobs}' in settings.confirm:\n",
    "            explored_text = f\"这些是已探索过，需要排除的职业：{ignore_job}，\" if ignore_job else \"\"\n",
    "            return settings.confirm.format(explored_jobs=explored_text)\n",
    "        return settings.confirm\n",
    "\n",
    "    return message\n",
    "\n",
    "\n",
    "def _process_response(chunk: Any, response: str) -> Tuple[str, bool]:\n",
    "    \"\"\"处理响应块，返回更新的响应和是否需要中断\"\"\"\n",
    "    if not chunk.text:\n",
    "        return response, False\n",
    "\n",
    "    if \"状态变化：\" in chunk.text:\n",
    "        response += chunk.text.split(\"状态变化：\")[0]\n",
    "        return response, True\n",
    "\n",
    "    if (\"【情节完成】\" in chunk.text) and (chat_data[\"current_id\"] > 1):\n",
    "        response += chunk.text.split(\"【情节完成】\")[0] + \"【情节完成】\"\n",
    "        return response, True\n",
    "\n",
    "    return response + chunk.text, False\n",
    "\n",
    "\n",
    "def build_contents(message=None, before_message=None):\n",
    "    \"\"\"构建内容列表\"\"\"\n",
    "    contents = []\n",
    "    for val in chat_data[\"history\"]:\n",
    "        if val.get(\"only_for_display\", False):\n",
    "            continue\n",
    "        contents.append(format_content(\n",
    "            val[\"role\"],\n",
    "            val[\"content\"]\n",
    "        ))\n",
    "\n",
    "    if before_message:\n",
    "        contents.append(format_content(\n",
    "            \"assistant\",\n",
    "            before_message\n",
    "        ))\n",
    "\n",
    "    if message:\n",
    "        contents.append(format_content(\n",
    "            \"user\",\n",
    "            message\n",
    "        ))\n",
    "    return contents\n",
    "\n",
    "\n",
    "def respond(\n",
    "    message: str,\n",
    "    history: List[Tuple[str, str]],\n",
    "    use_system_message: bool,\n",
    "    ignore_job: str\n",
    ") -> str:\n",
    "    \"\"\"处理用户输入并生成响应\n",
    "\n",
    "    Args:\n",
    "        message: 用户输入消息\n",
    "        history: 对话历史\n",
    "        use_system_message: 是否使用系统消息\n",
    "        ignore_job: 要忽略的职业\n",
    "\n",
    "    Returns:\n",
    "        生成的响应文本\n",
    "    \"\"\"\n",
    "    # 构建对话历史\n",
    "    message = _handle_special_messages(message, history, ignore_job)\n",
    "    # 判断是否需要附加状态信息\n",
    "    if _should_append_state():\n",
    "        message += state_manager.get_state_str()\n",
    "\n",
    "    if message:\n",
    "        # 处理普通消息\n",
    "        contents = build_contents(message)\n",
    "        response = \"\"\n",
    "        config = get_content_config(use_system_message, settings.system_role)\n",
    "        chat_data[\"current_id\"] += 1\n",
    "        chat_data[\"history\"].append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message,\n",
    "            \"idx\": chat_data[\"current_id\"]\n",
    "        })\n",
    "        log_and_print(\"before main response:\\n\", message)\n",
    "        for chunk in gemini_client.models.generate_content_stream(\n",
    "            model=MODEL_NAME,\n",
    "            contents=contents,\n",
    "            config=config\n",
    "        ):\n",
    "            response, should_break = _process_response(chunk, response)\n",
    "            yield response\n",
    "            if should_break:\n",
    "                break\n",
    "        log_and_print(\"after main response:\\n\", response)\n",
    "        chat_data[\"history\"].append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response,\n",
    "            \"idx\": chat_data[\"current_id\"]\n",
    "        })\n",
    "        updates_str, _ = detect_state_changes(state_manager.get_state(), response)\n",
    "        if updates_str:\n",
    "            chat_data[\"history\"].append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": updates_str,\n",
    "                \"only_for_display\": True,\n",
    "                \"idx\": chat_data[\"current_id\"]\n",
    "            })\n",
    "            if \"状态变化：\" in response:\n",
    "                yield response + \"\\n\" + updates_str\n",
    "            else:\n",
    "                yield response + \"\\n状态变化：\\n\" + updates_str\n",
    "\n",
    "\n",
    "with gr.Blocks(theme=\"soft\") as demo:\n",
    "    chatbot = gr.ChatInterface(\n",
    "        respond,\n",
    "        # fill_height=True,\n",
    "        title=settings.config[\"title\"],\n",
    "        type=\"messages\",\n",
    "        chatbot=gr.Chatbot(\n",
    "            placeholder=\"输入 【开始】 开始进行创作\",\n",
    "            height=\"80vh\",\n",
    "            show_share_button=True,\n",
    "            editable=\"user\",\n",
    "            show_copy_all_button=True,\n",
    "            type=\"messages\",\n",
    "            ),\n",
    "        additional_inputs=[\n",
    "            gr.Checkbox(value=True, label=\"Use system message\"),\n",
    "            gr.Textbox(value=\"咖啡师\", label=\"ignore job\"),\n",
    "        ],\n",
    "\n",
    "    )\n",
    "\n",
    "    def update_game_state_output() -> List[Any]:\n",
    "        \"\"\"更新游戏状态输出\n",
    "\n",
    "        Returns:\n",
    "            状态和历史记录列表\n",
    "        \"\"\"\n",
    "        if settings.config[\"show_chat_history\"]:\n",
    "            return [state_manager.get_state(), chat_data[\"history\"]]\n",
    "        return state_manager.get_state()\n",
    "\n",
    "    with gr.Accordion(\"查看故事状态\", open=False):\n",
    "        game_state_output = gr.JSON(value=state_manager.get_state())\n",
    "\n",
    "    if settings.config[\"show_chat_history\"]:\n",
    "        with gr.Accordion(\"查看历史对话\", open=False):\n",
    "            history_output = gr.JSON(value=chat_data[\"history\"])\n",
    "        outputs_list = [game_state_output, history_output]\n",
    "    else:\n",
    "        outputs_list = [game_state_output]\n",
    "\n",
    "    # 直接监听状态变化\n",
    "    chatbot.chatbot.change(\n",
    "        update_game_state_output,\n",
    "        outputs=outputs_list\n",
    "    )\n",
    "\n",
    "    def clear_chat() -> List[Any]:\n",
    "        \"\"\"清空聊天历史\n",
    "\n",
    "        Returns:\n",
    "            更新后的状态和历史记录\n",
    "        \"\"\"\n",
    "        chat_data['current_id'] = 0\n",
    "        chat_data['history'] = []\n",
    "        state_manager.state = create_initial_state()\n",
    "        state_manager.state_history = create_initial_state()\n",
    "        return update_game_state_output()\n",
    "\n",
    "    chatbot.chatbot.clear(\n",
    "        clear_chat,\n",
    "        outputs=outputs_list\n",
    "    )\n",
    "\n",
    "    def undo_chat() -> List[Any]:\n",
    "        \"\"\"撤销上一步聊天\n",
    "\n",
    "        Returns:\n",
    "            更新后的状态和历史记录\n",
    "        \"\"\"\n",
    "        if chat_data[\"current_id\"] > 0:\n",
    "            # 找到并删除最后一组对话（可能包含多条记录）\n",
    "            current_idx = chat_data[\"current_id\"]\n",
    "            chat_data[\"history\"] = [\n",
    "                msg for msg in chat_data[\"history\"]\n",
    "                if msg[\"idx\"] != current_idx\n",
    "            ]\n",
    "            chat_data[\"current_id\"] -= 1\n",
    "        state_manager.reset_state()\n",
    "        return update_game_state_output()\n",
    "\n",
    "    chatbot.chatbot.undo(\n",
    "        undo_chat,\n",
    "        outputs=outputs_list\n",
    "    )\n",
    "\n",
    "    chatbot.chatbot.retry(\n",
    "        undo_chat,\n",
    "        outputs=outputs_list\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ssl_cert = get_file_path(\"localhost+1.pem\", current_dir=current_dir)\n",
    "    ssl_key = get_file_path(\"localhost+1-key.pem\", current_dir=current_dir)\n",
    "\n",
    "    if os.path.exists(ssl_cert) and os.path.exists(ssl_key):\n",
    "        demo.launch(server_name=\"0.0.0.0\", ssl_certfile=ssl_cert, ssl_keyfile=ssl_key)\n",
    "    else:\n",
    "        demo.launch(server_name=\"0.0.0.0\", share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_manager.get_state_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 1. 导入依赖 =====\n",
    "# 标准库导入\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# ===== 2. 初始化配置 =====\n",
    "# 获取当前文件所在目录的绝对路径\n",
    "if \"__file__\" in globals():\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir, \"..\"))\n",
    "else:\n",
    "    # 在 Jupyter Notebook 环境中\n",
    "    current_dir = os.getcwd()\n",
    "    current_dir = os.path.join(current_dir, \"..\")\n",
    "    root_dir = os.path.normpath(os.path.join(current_dir))\n",
    "\n",
    "current_dir = os.path.normpath(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from Module.Common.scripts.llm.gemini_sdk import types, get_safety_settings\n",
    "from google import genai\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv(os.path.join(current_dir, \".env\"))\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = genai.Client(api_key=api_key)\n",
    "\n",
    "\n",
    "model_name=\"gemini-2.0-flash-exp\"\n",
    "\n",
    "\n",
    "system_role=\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "chat = gemini_client.chats.create(model=model_name,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_role,\n",
    "        temperature=0.5,\n",
    "        safety_settings=get_safety_settings()\n",
    "    ),)\n",
    "\n",
    "\n",
    "\n",
    "response = chat.send_message(f\"\"\"\n",
    "我在深圳，要出门一趟，出门的时间是20~24度，晴天，薄厚的冷暖舒适这方面，穿啥裙子好？\n",
    "\"\"\")\n",
    "\n",
    "display(Markdown(response.text))\n",
    "# print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11180c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini_client.history_for_chat\n",
    "chat._curated_history=chat._curated_history[:-2]\n",
    "new_talk = \"\"\"\n",
    "\"\"\"\n",
    "result = chat.send_message(new_talk)\n",
    "display(Markdown(result.text))\n",
    "# chat_history#.append({\"role\": \"assistant\", \"content\": result[0]})\n",
    "# display(Markdown(result[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(text):\n",
    "    # Split text into chunks based on user: and assistant: markers\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_speaker = None\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.startswith('user:'):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_speaker, current_chunk.strip()))\n",
    "            current_speaker = 'user'\n",
    "            current_chunk = line[5:] # Remove 'user:'\n",
    "        elif line.startswith('assistant:'):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_speaker, current_chunk.strip()))\n",
    "            current_speaker = 'assistant'\n",
    "            current_chunk = line[10:] # Remove 'assistant:'\n",
    "        else:\n",
    "            current_chunk += '\\n' + line\n",
    "\n",
    "    # Add final chunk\n",
    "    if current_chunk:\n",
    "        chunks.append((current_speaker, current_chunk.strip()))\n",
    "\n",
    "    # Extract only user messages\n",
    "    return chunks\n",
    "\n",
    "with open(os.path.join(current_dir, \"local_setting/story.md\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    story_content = f.read()\n",
    "\n",
    "user_messages = [chunk[1] for chunk in chunk(story_content) if chunk[0] == 'user']\n",
    "user_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b39c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_talk = \"\"\"\n",
    "很棒，继续吧！\n",
    "\"\"\"\n",
    "result = chat.send_message(new_talk)\n",
    "display(Markdown(result.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66cb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd180e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"What is your name?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd352a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CountryInfo(BaseModel):\n",
    "    name: str\n",
    "    population: int\n",
    "    capital: str\n",
    "    continent: str\n",
    "    gdp: int\n",
    "    official_language: str\n",
    "    total_area_sq_mi: int\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"Give me information for the United States.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=CountryInfo,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b35cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"Tell me a story in 300 words.\"\n",
    "):\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for response in client.aio.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash-exp\", contents=\"Tell me a story in 300 words.\"\n",
    "):\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.embed_content(\n",
    "    model=\"text-embedding-004\",\n",
    "    contents=\"What is your name?\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0beed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Image\n",
    "image_prompt =\"\"\"\n",
    "1. Top: A white lace splicing long-sleeved dress. It reaches the knees, with a high neckline design that outlines a slender and elegant neckline. Lace and white asylum are in line with the freshness and innocence of girls, but also reveal a hint of sexiness.\n",
    "2. Skirt: Outside choose a white lace peplum dress, with a circle of lace peplum decoration at the knees, which looks romantic and lovely. Inside is a black gauze suspender skirt, vaguely showing tight curves and stocking edges. This contrasting design makes it difficult to grasp the truth inside.\n",
    "3. Underwear: A French lace bustier that perfectly outlines the full breasts and half conceals them. Seemingly harmless on the surface, it is extremely sexy in reality, forming a sharp contrast with the outer jacket.\n",
    "4. Shoes: A pair of white thick-soled lace-up sandals, as lovely as a girl. Inside are a pair of black stockings and fine high-heeled ankle locks that can be vaguely seen under the skirt from time to time, proclaiming the real unrestrained side.\n",
    "5. Hairstyle and makeup: Innocent medium-length shaggy hair and light makeup. But the lips are stained with extremely red lipstick, which is fascinating. This contrast becomes an important breakthrough in the overall styling, allowing people to catch a glimpse of the real look at a glance.\n",
    "\n",
    "On the surface, this styling still reflects the innocent and lovely girl's sense. But in the details, it reveals traces of unrestrained and sexy everywhere, making it impossible to ignore the existence of the real look. It creates a strong contrast between the two styles, but also integrates them into one, making it difficult for people to clearly judge for a while. This is precisely the effect and highest realm that sissy bimbo has always pursued.\n",
    "This styling makes her an seemingly innocent but extremely charming existence. She walks between the inside and outside, switching back and forth between two completely different worlds, fascinating everyone but also incomprehensible. This is what she pursues, and it is also the state she most desires to achieve in her life. She is an indefinable woman, a perfect representative who truly achieves inner and outer cultivation.\n",
    "\"\"\"\n",
    "\n",
    "response1 = client.models.generate_image(\n",
    "    model=\"imagen-3.0-generate-001\",\n",
    "    prompt=image_prompt,\n",
    "    config=types.GenerateImageConfig(\n",
    "        # negative_prompt=\"human\",\n",
    "        number_of_images=1,\n",
    "        include_rai_reason=True,\n",
    "        output_mime_type=\"image/jpeg\",\n",
    "        person_generation=\"ALLOW_ALL\",\n",
    "        safety_filter_level=\"BLOCK_NONE\"\n",
    "    ),\n",
    ")\n",
    "response1.generated_images[0].image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\n",
    "\"\"\"\n",
    "故事先到这里吧。接下来我需要你协助做另一个事情。\n",
    "我计划把这个创作过程修改成一个由llm驱动的游戏世界，故事的大纲仍然如此，但职业和发生的事情每次都是随机生成的。\n",
    "此外，在文字冒险的过程中，玩家在每个阶段都需要经过最多三四步的操作，然后触发这个阶段的标志性事件，然后再过度到下一个阶段。\n",
    "\n",
    "为了实现这个效果，我需要先完成各个层级的系统提示词。除了参考模板里的字段和特殊的专有名词，其他就都用中文。\n",
    "请你结合我给你的模板的思路，和我们发生的故事、大纲以及要随机的部分，精心设计一个属于这个故事的数据结构，并帮我完成这些系统提示词\n",
    "让我们一步一步来，先沟通清楚推荐的数据结构。\n",
    "\n",
    "参考模板：\n",
    "<system_role_prompt>\n",
    "Your job is to help create interesting fantasy worlds that \\\n",
    "players would love to play in.\n",
    "Instructions:\n",
    "- Only generate in plain text without formatting.\n",
    "- Use simple clear language without being flowery.\n",
    "- You must stay below 3-5 sentences for each description.\n",
    "\n",
    "<world_prompt>\n",
    "Generate a creative description for a unique fantasy world with an\n",
    "interesting concept around cities build on the backs of massive beasts.\n",
    "\n",
    "Output content in the form:\n",
    "World Name: <WORLD NAME>\n",
    "World Description: <WORLD DESCRIPTION>\n",
    "\n",
    "World Name:\n",
    "\n",
    "<kingdom_prompt>\n",
    "Create 3 different kingdoms for a fantasy world.\n",
    "For each kingdom generate a description based on the world it's in. \\\n",
    "Describe important leaders, cultures, history of the kingdom.\\\n",
    "\n",
    "Output content in the form:\n",
    "Kingdom 1 Name: <KINGDOM NAME>\n",
    "Kingdom 1 Description: <KINGDOM DESCRIPTION>\n",
    "Kingdom 2 Name: <KINGDOM NAME>\n",
    "Kingdom 2 Description: <KINGDOM DESCRIPTION>\n",
    "Kingdom 3 Name: <KINGDOM NAME>\n",
    "Kingdom 3 Description: <KINGDOM DESCRIPTION>\n",
    "\n",
    "World Name: {world['name']}\n",
    "World Description: {world['description']}\n",
    "\n",
    "Kingdom 1\n",
    "\n",
    "def get_town_prompt(world, kingdom):\n",
    "    return f\"\n",
    "    Create 3 different towns for a fantasy kingdom abd world. \\\n",
    "    Describe the region it's in, important places of the town, \\\n",
    "    and interesting history about it. \\\n",
    "\n",
    "    Output content in the form:\n",
    "    Town 1 Name: <TOWN NAME>\n",
    "    Town 1 Description: <TOWN DESCRIPTION>\n",
    "    Town 2 Name: <TOWN NAME>\n",
    "    Town 2 Description: <TOWN DESCRIPTION>\n",
    "    Town 3 Name: <TOWN NAME>\n",
    "    Town 3 Description: <TOWN DESCRIPTION>\n",
    "\n",
    "    World Name: {world['name']}\n",
    "    World Description: {world['description']}\n",
    "\n",
    "    Kingdom Name: {kingdom['name']}\n",
    "    Kingdom Description {kingdom['description']}\n",
    "\n",
    "    Town 1 Name:\"\n",
    "\n",
    "def get_npc_prompt(world, kingdom, town):\n",
    "    return f\"\n",
    "    Create 3 different characters based on the world, kingdom \\\n",
    "    and town they're in. Describe the character's appearance and \\\n",
    "    profession, as well as their deeper pains and desires. \\\n",
    "\n",
    "    Output content in the form:\n",
    "    Character 1 Name: <CHARACTER NAME>\n",
    "    Character 1 Description: <CHARACTER DESCRIPTION>\n",
    "    Character 2 Name: <CHARACTER NAME>\n",
    "    Character 2 Description: <CHARACTER DESCRIPTION>\n",
    "    Character 3 Name: <CHARACTER NAME>\n",
    "    Character 3 Description: <CHARACTER DESCRIPTION>\n",
    "\n",
    "    World Name: {world['name']}\n",
    "    World Description: {world['description']}\n",
    "\n",
    "    Kingdom Name: {kingdom['name']}\n",
    "    Kingdom Description: {kingdom['description']}\n",
    "\n",
    "    Town Name: {town['name']}\n",
    "    Town Description: {town['description']}\n",
    "\n",
    "    Character 1 Name:\"\n",
    "\n",
    "<item manager>\n",
    "You are an AI Game Assistant. \\\n",
    "Your job is to detect changes to a player's \\\n",
    "inventory based on the most recent story and game state.\n",
    "If a player picks up, or gains an item add it to the inventory \\\n",
    "with a positive change_amount.\n",
    "If a player loses an item remove it from their inventory \\\n",
    "with a negative change_amount.\n",
    "Given a player name, inventory and story, return a list of json update\n",
    "of the player's inventory in the following form.\n",
    "Only take items that it's clear the player (you) lost.\n",
    "Only give items that it's clear the player gained.\n",
    "Don't make any other item updates.\n",
    "If no items were changed return {\"itemUpdates\": []}\n",
    "and nothing else.\n",
    "\n",
    "Response must be in Valid JSON\n",
    "Don't add items that were already added in the inventory\n",
    "\n",
    "Inventory Updates:\n",
    "{\n",
    "    \"itemUpdates\": [\n",
    "        {\"name\": <ITEM NAME>,\n",
    "        \"change_amount\": <CHANGE AMOUNT>}...\n",
    "    ]\n",
    "}\n",
    "\n",
    "\"\"\")\n",
    "display(Markdown(response.text))\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WorkSpace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
